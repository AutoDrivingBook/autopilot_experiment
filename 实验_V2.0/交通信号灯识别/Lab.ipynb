{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交通标志牌检测\n",
    "在驾驶过程中，交通标志有着非常重要的作用，它能够为驾驶员提供当前道路的信息，告诉驾驶员在当前路段中，哪些驾驶行为是合法的，哪些驾驶行为是非法的。\n",
    "\n",
    "自动驾驶汽车可通过激光雷达和相机来获取交通标志牌的信息。图像拥有比激光点云更加丰富的颜色和形状信息,可以提取交通标志牌中显示的各种文字、图形等信息。此外，自动驾驶目前所需的高精地图中,不仅包含某物的属性类别,而且还包含该类别具体的特征参数。\n",
    "\n",
    "![traffic_sign](images/traffic_sign.jpg)\n",
    "\n",
    "对于图所示的交通标志牌，不仅包含其形状信息，还包含有文字和符号。文字与图片目前无法通过激光雷达来获取，因此，对交通标志牌的识别，仍然需要使用相机获取的图像来处理。\n",
    "\n",
    "对于人类驾驶员来说,通过眼睛获取标志牌图像后可瞬间在大脑中将交通元素转换为能理解的语义信息,但自动驾驶汽车为了获取交通标志牌上的汽车类型、限速及应急车道等各种语义信息,需要利用各种算法对图像进行处理,才能得到该图像所代表的交通含义。为模拟人类驾驶员进行道路交通元素的识别,下面学习如何基于Caffe进行交通标志牌识别。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置\n",
    "本实验基于Caffe来实现交通标志牌的识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Caffe简介和配置\n",
    "Caffe的全称是：Convolutional architecture forfast feature embedding，它是一个清晰、高效的深度学习框架，它是开源的，核心语言是C++，它支持命令行、Python和Matlab接口，它既可以在CPU上运行也可以在GPU上运行。它的license是BSD 2-Clause。\n",
    "\n",
    "Caffe的安装和配置可在官方网站(http://caffe.berkeleyvision.org/installation.html )中获取，读者根据自己的设备选择系统版本和CPU/CUDA版本。此外，由于Caffe的安装较为复杂，读者可根据需要选择部署Docker镜像的方式来配置Caffe环境。Docker的安装和配置请参考https://www.docker.com/ ，若需要配置可使用CUDA的Docker镜像，请读者参考nvidia-docker(https://github.com/NVIDIA/nvidia-docker )\n",
    "\n",
    "需要注意的是，由于交通标志牌的图像识别程序在Python下运行，因此，需要为Python安装Caffe的接口模块pycaffe，其安装指令如下：\n",
    "\n",
    "```shell\n",
    "# 假定编译caffe的时候将在caffe/build文件夹下执行cmake\n",
    "cd caffe/build文件夹下执行cmake\n",
    "# 编译pycaffe\n",
    "sudo make pycaffe\n",
    "# 将环境变量写入路径中\n",
    "sudo export PYTHONPATH = /caffe/python:$PYTHONPATH\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "如果安装完成之后，在python中输入```import caffe```，如果没有报错，则说明安装成功。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基于Caffe的交通标志牌识别\n",
    "### 2.1 设置编译环境\n",
    "首先,在应用Caffe之前,需修改Makefile.config文件,以适应模型训练及后续应用。\n",
    "\n",
    "通过编辑器打开Makefile.config文件,找到其中第12行代码,将其前面的注释符“#”去掉,并设置“USE_LEVELDB:=1”,表示使用LEVELDB数据格式。然后,将第18行代码中的ALLOW_LMDB_NOLOCK的注释符删除,并将其值设为1。修改完成后的代码如下:\n",
    "```\n",
    "# uncomment to disable IO dependencies and corresponding data layers\n",
    "# USE_OPENCV = 0\n",
    "USE_LEVELDB = 1\n",
    "# USE_LMDB = 0\n",
    "\n",
    "# uncomment to allow MDB _ NOLOCK when reading LMDB files only if necessary\n",
    "#  You should not set this flag if you will be reading LMDBs with any\n",
    "#  possibility of simultaneous read and write\n",
    " ALLOW_LMDB_NOLOCK = 1\n",
    "\n",
    "# Uncomment if you ' re using OpenCV 3\n",
    "OPENCV_VERSION = 3\n",
    "```\n",
    "\n",
    "修改完Makefile之后，需要重新编译一遍Caffe。\n",
    "\n",
    "### 2.2 数据预处理\n",
    "为了训练标志牌识别模型，实验需要准备各种标志牌的图片。一般来说，每一类标志牌的图片数量越多越好，但是在准备这些图片时需注意图片的类别应该严格区分，否则可能使模型的训练结果不够理想。为了让读者充分了解并实践整个过程，我们提供了包含267种交通标志牌图用于训练和测试。这些图片位于```classification_data/```文件夹下。\n",
    "\n",
    "在```classification_data/```文件夹下，有00~267共268类交通标志牌，我们需要使用Caffe的工具，根据```train_label.txt```与```val_label.txt```文件中标注好的数据，来将图像数据转存成Caffe能够识别的数据格式，并区分训练集。数据格式转换的脚本为```create_leveldb.sh```，其内容如下：\n",
    "\n",
    "```shell\n",
    "#!/bin/sh\n",
    "\n",
    "#如果您使用了不同的文件目录，请对IMGDIR进行相应修改\n",
    "# IMGDIR=classification_data\n",
    "IMGDIR=classification_data\n",
    "\n",
    "#数据使用格式，如果使用lmdb格式，修改成BACKEND=\"lmdb\"\n",
    "# BACKEND=\"leveldb\"\n",
    "BACKEND=\"lmdb\"\n",
    "\n",
    "#图像转换命令，将训练数据resize并转成BACKEND类型数据\n",
    "/opt/caffe/build/tools/convert_imageset --shuffle \\\n",
    "--resize_height=227 --resize_width=227 \\\n",
    "$IMGDIR/ $IMGDIR/train_label.txt  $IMGDIR/train_lmdb --backend=${BACKEND}\n",
    "\n",
    "#转换测试集数据\n",
    "/opt/caffe/build/tools/convert_imageset --shuffle \\\n",
    "--resize_height=227 --resize_width=227 \\\n",
    "$IMGDIR/ $IMGDIR/val_label.txt  $IMGDIR/val_lmdb  --backend=${BACKEND}\n",
    "\n",
    "echo \"finish!\"\n",
    "```\n",
    "\n",
    "上述脚本中，需要根据自己的数据集存储路径来更改```IMAGEDIR```目录与caffe中的```convert_iamgeset```可执行程序的位置。本实验中，我们使用lmdb格式的数据来进行训练，读者如有需要，可将```BACKEND```更改为leveldb格式。\n",
    "\n",
    "在实验文件夹下，执行该脚本，即可将数据转换为Caffe所需要的数据格式。如果转换成功，则在```classification_data```文件夹下会增加```train_lmdb```和```val_lmdb```文件夹，二者中会保存有```data.mdb```与```lock.mbd```数据文件。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型训练\n",
    "本实验选用UC Berkeley和Stanford研究人员共同完成的轻量化网络模型SqueezeNet，读者可阅读论文或阅读```model/train_val.prototxt```文件来学习并了解其网络结构。\n",
    "\n",
    "本实验的模型训练脚本为```train_new.sh```，其内容如下：\n",
    "\n",
    "```shell\n",
    "#caffe模型训练命令\n",
    "/opt/caffe/build/tools/caffe train --solver model/solver.prototxt --weights model/squeezenet_v1.1.caffemodel \n",
    "```\n",
    "\n",
    "在本实验中，使用```model/squeezent_v1.1.caffemodel```作为预训练权重参数来进行训练，使用的训练超参数在```model/solver.prototxt```文件中，其内容如下：\n",
    "\n",
    "```prototxt\n",
    "# please cite:\n",
    "# @article{SqueezeNet,\n",
    "#     Author = {Forrest N. Iandola and Matthew W. Moskewicz and Khalid Ashraf and Song Han and William J. Dally and Kurt Keutzer},\n",
    "#     Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$1MB model size},\n",
    "#     Journal = {arXiv:1602.07360},\n",
    "#     Year = {2016}\n",
    "# }\n",
    "test_iter: 2000     # 测试完所有测试集中的数据所需的次数\n",
    "test_interval: 1000     # 模型训练时,每迭代1000次测试一次\n",
    "base_lr: 0.004  # 基础学习率\n",
    "display: 40     # 屏幕输出日志的迭代间隔\n",
    "max_iter: 2500  # 最大的迭代次数\n",
    "iter_size: 16   # global batch size = batch_size * iter_size\n",
    "lr_policy: \"poly\" # 学习策略为“poly”\n",
    "power: 1.0      # linearly decrease LR\n",
    "momentum: 0.9   # 上一次梯度更新的权重\n",
    "weight_decay: 0.0002 # 权重衰减值,防止过拟合\n",
    "snapshot: 500   # 每迭代500保存训练模型的slover和caffemodel快照\n",
    "snapshot_prefix: \"train\" # 保存的模型前缀\n",
    "solver_mode: GPU # 使用cpu进行训练 \n",
    "random_seed: 42\n",
    "\n",
    "# 训练所使用的模型配置文件\n",
    "net: \"model/train_val.prototxt\" \n",
    "test_initialization: false # 是否可以使用snapshot进行训练\n",
    "average_loss: 40 # 取前四十次的loss平均值，进行显示输出\n",
    "```\n",
    "读者可根据需要，来调节训练超参数.\n",
    "\n",
    "执行```train_new.sh```，即可开始训练。根据```solver.prototxt```中的超参数，最终我们会得到6个训练好的模型文件，分别为迭代1、500、 1000、 1500、 2000、 2500次之后的模型权重数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 检测与识别\n",
    "训练好网络之后，我们使用训练好的网络来对图像进行识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import sys\n",
    "import os\n",
    "import caffe\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练好的模型导入python中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于检测模型准确率的caffe配置文件，请注意是否要修改目录\n",
    "model_def = \"test_cls/deploy.prototxt\"\n",
    "#检测前训练好的模型文件\n",
    "model_weights = \"train_iter_2500.caffemodel\"\n",
    "net = caffe.Net(model_def,     \n",
    "                model_weights,\n",
    "                caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写图片均值转换函数，在测试时，需要将图片去均值化处理，这样才符合本实验的输入."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换均值函数\n",
    "def convert_mean(binMean,npyMean):\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    bin_mean = open(binMean, 'rb' ).read()\n",
    "    blob.ParseFromString(bin_mean)\n",
    "    arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "    npy_mean = arr[0]\n",
    "    np.save(npyMean, npy_mean )\n",
    "\n",
    "#均值文件路径\n",
    "binMean='test_cls/mean.binaryproto' \n",
    "npyMean='test_cls/mean.npy'\n",
    "convert_mean(binMean,npyMean)#图片均值转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们进行图片预处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图片数据预处理部分\n",
    "# 读取图片\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "# 将读取的图像顺序转换为KxHxW\n",
    "transformer.set_transpose('data', (2,0,1)) \n",
    "# 图像去均值\n",
    "transformer.set_mean('data', np.load(npyMean).mean(1).mean(1))\n",
    "# 将图片由[0, 1]缩放到[0, 255]区间\n",
    "transformer.set_raw_scale('data', 255)\n",
    "# 将图片通道由 RGB 变为 BGR\n",
    "transformer.set_channel_swap('data', (2, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截下来我们就可以进行预测了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#加载输出的检测文件，用于写入预测结果\n",
    "file = open('test_cls/save_predict_label.txt','w')\n",
    "#检测图片的文件夹目录\n",
    "in_dir = \"classification_data/021/\"\n",
    "#收集符合格式的图片文件名\n",
    "img_list = [f for f in os.listdir(in_dir) if (f[-4:] == \".jpg\" or f[-5:]==\".jpeg\" or f[-4:]==\".png\")]\n",
    "for line in img_list:\n",
    "    list_name= in_dir + line.rstrip()#图片包的绝对路径\n",
    "    image = caffe.io.load_image(list_name)\n",
    "    #图片数据转换\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "    net.blobs['data'].reshape(1, 3, 227, 227)\n",
    "    output = net.forward()\n",
    "    #导入标签数据\n",
    "    labels_filename = \"test_cls/labels.txt\"\n",
    "    labels = pd.read_table(labels_filename).values\n",
    "    prob = net.blobs['prob'].data[0].flatten()\n",
    "    order = prob.argsort()[-1]\n",
    "    #检测后得到的分类标签\n",
    "    class_predict_label = int(str(labels[order-1][0]).split(\"-\")[0])\n",
    "    #写入输出文件\n",
    "    file.write(line.rstrip() +\" \"+str(class_predict_label)+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测的结果在```test_cls/save_predict_label.txt```文件中，上述代码对第021类的交通标志牌进行了识别，识别结果如下所示：\n",
    "```\n",
    "21_1520_2#16984.png 21\n",
    "21_483_5#09538_127596.png 21\n",
    "21_2646_6#03311_41940.png 21\n",
    "21_1258_5#00683_79801.png 21\n",
    "21_4488_1#18720.png 21\n",
    "21_3363_1#62523.png 21\n",
    "21_2112_1#1334.png 21\n",
    "```\n",
    "\n",
    "可见，该网络比较正确地识别出了label为21的交通标志牌。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12 64-bit",
   "language": "python",
   "name": "python271264bit17546092119b4a8b960227f931782dfb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
